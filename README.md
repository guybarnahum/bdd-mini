# ğŸš— BDD-Mini: Lightweight Dataset Builder

**BDD-Mini** is a specialized tool designed to create a "Mini-BDD100K" dataset for Multi-Object Tracking (MOT) training.

Instead of downloading the massive 32GB+ dataset, this tool **streams** the data from official mirrors, extracting only the specific video sequences and frames you need. It automatically formats the data into **COCO-Video** (for Transformers like MOTIP) and **MOTChallenge** (for TrackEval) formats.

---

## ğŸš€ Features

* **Smart Streaming:** Connects to remote zip archives via HTTP Range Requests to download *only* the frames you need.
* **Resume Capability:** Images are cached locally in `data/image_cache`. If you interrupt the script (`Ctrl-C`), simply run it again to resume exactly where you left off.
* **Multi-Format Export:** Generates both **COCO-Video** JSONs (Train/Val/Test) and **MOTChallenge** (`gt.txt`) formats simultaneously.
* **Configurable Splits:** Define your own Train/Val/Test ratios in `config.toml` (e.g., 70/15/15).
* **Visualization Tools:** Includes a renderer to generate MP4 movies with bounding boxes directly from your generated labels (COCO or MOT) using FFmpeg.
* **Defensive Parsing:** Validates source data integrity to prevent crashes on malformed JSONs.

---

## ğŸ“‚ Project Structure
```bash
bdd-mini/
â”œâ”€â”€ config.toml          
â”œâ”€â”€ setup.sh             # ğŸ› ï¸ Installation script (creates venv)
â”œâ”€â”€ builder.py           # ğŸ—ï¸ Main script (streams, splits & builds dataset)
â”œâ”€â”€ render.py            # ğŸ¬ Visualization tool (renders MP4s from labels)
â”œâ”€â”€ cleanup.sh           # ğŸ§¹ Safer cleanup (protects image cache)
â”œâ”€â”€ venv/                # ğŸ Virtual environment
â”œâ”€â”€ data/                # ğŸ“¦ Local cache (labels & image_cache)
â””â”€â”€ output/              # ğŸ“¤ Final Dataset Location
    â””â”€â”€ mini_bdd/
        â”œâ”€â”€ annotations/ # ğŸ“„ COCO Format (train.json, val.json)
        â”œâ”€â”€ mot_format/  # ğŸ“„ MOT Format (gt/gt.txt, seqinfo.ini)
        â””â”€â”€ images/      # ğŸ–¼ï¸ Images sorted by split (train/val/test)
```

## ğŸ› ï¸ Installation

1.  **Run the Setup Script:**
    This creates the Python virtual environment and installs dependencies (`remotezip`, `tqdm`, `opencv-python`).

    chmod +x setup.sh
    ./setup.sh

2.  **Install FFmpeg (Optional but Recommended):**
    Required for `render.py` to generate visualization videos.
    * **Mac:** `brew install ffmpeg`
    * **Linux:** `sudo apt install ffmpeg`


## ğŸƒ Usage

### 1. Build the Dataset
Activate the environment and run the builder. It will download labels, select random videos, and stream frames.

source venv/bin/activate
python3 builder.py

* **Interrupting:** You can hit `Ctrl-C` at any time. Progress is saved in `data/image_cache`. Run the command again to resume instantly.

### 2. Visualize the Data
Verify your dataset by rendering a video with bounding boxes drawn from the generated labels.

#### Render a random video from the Training set (COCO format)
```bash
python3 render.py
```
#### Render from the Validation set
```bash
python3 render.py --split val
```

#### Verify MOTChallenge export format specifically
```bash
python3 render.py --format mot
```

**Output:** Videos are saved to `output/rendered/`.

### 3. Clean Up
To remove generated outputs (e.g., to re-roll random videos) while **keeping the downloaded image cache**:

```bash
./cleanup.sh
```
*(The script will ask for confirmation before deleting the cache).*


## âš™ï¸ Configuration (`config.toml`)

Control every aspect of the dataset generation here.

```bash
[dataset]
num_videos = 20           # Total videos to select
seed = 42                 # Random seed for reproducibility
output_dir = "output/mini_bdd"
frame_step = 5            # Sample 1 frame every N frames (5 = ~6FPS)

# Export Formats
# "coco" -> annotations/train.json (for MOTIP/MOTR)
# "mot"  -> mot_format/train/Video/gt/gt.txt (for TrackEval)
export_formats = ["coco", "mot"]

# Data Splits (Must sum to 1.0)
train_ratio = 0.70
val_ratio   = 0.15
test_ratio  = 0.15
```

## â“ Troubleshooting

* **"Streaming Error / Connection Reset"**
The script relies on the ETH Zurich mirror. If unstable, try again later or check your internet connection. The Resume feature ensures you don't lose progress.

* **"FFmpeg not found"**
If `render.py` fails, ensure ffmpeg is installed and in your system PATH.

* **"Dataset is empty"**
Check `config.toml`. If `num_videos` is too high (e.g., >200), the script might struggle to find enough matching sequences in the specific label zip file provided.

---

## ğŸ“ License
The BDD100K data is subject to the [BDD100K License](https://doc.bdd100k.com/license.html).